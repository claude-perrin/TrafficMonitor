{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2 \n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn \n",
    "import torch\n",
    "from conf import NUMBER_OF_CLASSES\n",
    "import datetime\n",
    "from torchvision.models.detection import ssd300_vgg16, ssd\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from conf import *\n",
    "import itertools\n",
    "sys.path.append('..')\n",
    "sys.path.append('../training')\n",
    "\n",
    "from inference.inference_helper import denormalize_polygon, preprocess_image, inference_filter_prediction\n",
    "from training.helper import get_test_data_loader\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.ops import box_iou\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_path1 = \"../models/Good_FasterRcnn_V1_model.pth\"\n",
    "model_path2 = \"../models/Good_FasterRcnn_V2_model.pth\"\n",
    "model_path3 = \"../models/Good_SSD_model.pth\"\n",
    "\n",
    "\n",
    "def load_model1(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path1)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path1} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "def load_model2(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path2)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path2} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "def get_ssd_detection_model(num_classes=NUMBER_OF_CLASSES):\n",
    "    ssd_model = ssd300_vgg16(weights=False)\n",
    "    num_anchors = ssd_model.anchor_generator.num_anchors_per_location()\n",
    "    out_channels = [512,1024,512,256,256,256]\n",
    "    # ssd_model.head = ssd.SSDHead(out_channels, num_anchors, num_classes+1)\n",
    "    state_dict= torch.load(model_path3)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    ssd_model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path3} is loaded successfuly\")\n",
    "\n",
    "    return ssd_model\n",
    "\n",
    "\n",
    "def save_test_img(img, target, prefix):\n",
    "    # img = img.permute(2,0,1).cpu().numpy()  # Convert to (height, width, channels)\n",
    "    # img = img.cpu().numpy()  # Convert to (height, width, channels)\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), 'test_output')):\n",
    "        os.makedirs(os.path.join(os.getcwd(), 'test_output'))\n",
    "    # cv2.imshow(img)\n",
    "    img_path = f\"./test_output/output_image_{prefix}.png\"\n",
    "    cv2.imwrite(img_path, img)\n",
    "    return img_path\n",
    "\n",
    "def plot_boxes(normalized_road_roi_polygon, results, frame):\n",
    "    \"\"\"\n",
    "    Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "    :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "    :param frame: Frame which has been scored.\n",
    "    :return: Frame with bounding boxes and labels ploted on it.\n",
    "    \"\"\"\n",
    "    label_bg_white = (255, 255, 255)\n",
    "    if len(results) != 0:\n",
    "        result = results\n",
    "    # for result in results:\n",
    "        for box, label,score in itertools.zip_longest(result['boxes'], result['labels'], result[\"scores\"]):\n",
    "            label = label.item()\n",
    "            box_color = BOX_COLOR[label]\n",
    "            x1, x2, x3, x4 = int(box[0].item()), int(box[1].item()), int(box[2].item()), int(box[3].item())\n",
    "            cv2.rectangle(frame, (x1,x2),(x3,x4), box_color, 2)\n",
    "            if score is not None:\n",
    "                cv2.rectangle(frame, (x1, x2-25), (x1+150, x2), label_bg_white, -1)\n",
    "                label_text = f'{class_to_label(label)}: {score:.2f}'\n",
    "                cv2.putText(frame, label_text, (x1, x2 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, box_color, 2)\n",
    "    cv2.polylines(frame, [np.array(normalized_road_roi_polygon)], isClosed=True, color=(32, 32, 128), thickness=2)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def class_to_label(label):\n",
    "    return IDX_TO_CLASSES[label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL from volume: ../models/Good_FasterRcnn_V2_model.pth is loaded successfuly\n"
     ]
    }
   ],
   "source": [
    "# model1 = load_model1()\n",
    "model1 = load_model2()\n",
    "# model1 = get_ssd_detection_model()\n",
    "\n",
    "model1.eval()\n",
    "# model2.eval()\n",
    "# model3.eval()\n",
    "model_name = \"V2\"\n",
    "original_image_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====[INFO] Get test data loader test_dir:\n",
      "FOUND INCONSISTENT FILE: _complex.jpg, \n",
      "label not found: _complex.txt\n",
      "FOUND INCONSISTENT FILE: _simple.jpg, \n",
      "label not found: _simple.txt\n",
      "=====[INFO] Got test loader\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m denormalized_road_roi_polygon \u001b[38;5;241m=\u001b[39m denormalize_polygon(image_dim, ROAD_ROI_POLYGON)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, targets,original_images) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mplot_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenormalized_road_roi_polygon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     save_test_img(frame, targets, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 91\u001b[0m, in \u001b[0;36mplot_boxes\u001b[0;34m(normalized_road_roi_polygon, results, frame)\u001b[0m\n\u001b[1;32m     89\u001b[0m     result \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# for result in results:\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m box, label,score \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mzip_longest(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboxes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     92\u001b[0m         label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     93\u001b[0m         box_color \u001b[38;5;241m=\u001b[39m BOX_COLOR[label]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "IOU_THRESHOLD = 0.4\n",
    "\n",
    "def generate_hist(output, target, label):\n",
    "    \n",
    "    output_mask = output['labels'] == label\n",
    "    target_mask = target['labels'] == label\n",
    "    output = {k: v[output_mask] for k, v in output.items()}\n",
    "    target = {k: v[target_mask] for k, v in target.items()}\n",
    "\n",
    "    ground_truth_boxes = target[\"boxes\"]\n",
    "    predicted_boxes = output[\"boxes\"]\n",
    "    if len(predicted_boxes) == 0:\n",
    "        predicted_boxes = torch.from_numpy(np.zeros_like(ground_truth_boxes))\n",
    "    print(\"ground_truth_boxes: \", ground_truth_boxes)\n",
    "    print(\"predicted_boxes: \", predicted_boxes)\n",
    "\n",
    "    iou_matrix = box_iou(ground_truth_boxes, predicted_boxes)\n",
    "    print(\"iou_matrix \\n\", iou_matrix)\n",
    "    conf_matrix = torch.zeros(len(ground_truth_boxes), len(predicted_boxes))\n",
    "    conf_matrix[iou_matrix > IOU_THRESHOLD] = 1\n",
    "    answers_ground_truth = conf_matrix.sum(axis=1)\n",
    "\n",
    "    print(\"CONF MATRIX \\n\", conf_matrix)\n",
    "    correct_boxes_prediction = answers_ground_truth.sum().item()\n",
    "    not_predicted_boxes = len(answers_ground_truth) - answers_ground_truth.sum().item()\n",
    "\n",
    "    answers_prediction = conf_matrix.sum(axis=0)\n",
    "    excessive_boxes = len(answers_prediction) - answers_prediction.sum().item()\n",
    "    return (correct_boxes_prediction, excessive_boxes, not_predicted_boxes)\n",
    "\n",
    "def save_hist(values, title, prefix):\n",
    "    categories = [\"Correct Box Prediction\", \"Excessive boxes\", \"Not Predicted Boxes\"]\n",
    "    sns.barplot(x=categories, y=values, palette=\"viridis\", orientation=\"vertical\")\n",
    "    print(\"VALUES: \", values)\n",
    "    # Add labels and title\n",
    "    plt.title(title)\n",
    "    plt.savefig(f'./graphs_output/histogram_{prefix}.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "dataloader = get_test_data_loader(1, \"./real_frames/\")\n",
    "image_dim = (960,1280)\n",
    "denormalized_road_roi_polygon = denormalize_polygon(image_dim, ROAD_ROI_POLYGON)\n",
    "\n",
    "for batch_idx, (data, targets,original_images) in enumerate(dataloader, 1):\n",
    "\n",
    "    frame = plot_boxes(targets[0], torch.clone(original_images[0]).numpy(), denormalized_road_roi_polygon)\n",
    "    save_test_img(frame, targets, f\"model_image\")\n",
    "\n",
    "    break\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model1(data)\n",
    "    outputs1 = inference_filter_prediction(outputs1, denormalized_road_roi_polygon)\n",
    "    for output, target, original_image in zip(outputs1, targets, original_images): \n",
    "        print(\"labels: \", output[\"labels\"])\n",
    "        idx = target[\"idx\"]\n",
    "        if idx == 0:\n",
    "            idx = \"complex\"\n",
    "        elif idx == 1:\n",
    "            idx = \"medium\"\n",
    "        elif idx == 2:\n",
    "            idx = \"simple\"\n",
    "\n",
    "        del target['idx']\n",
    "        hist_cars = generate_hist(output, target, 4)\n",
    "        hist_pedestrians = generate_hist(output, target, 3)\n",
    "        prefix = f\"{model_name}_{idx}\"\n",
    "\n",
    "        frame = plot_boxes(denormalized_road_roi_polygon, [output], torch.clone(original_image).numpy())\n",
    "        save_test_img(frame, output, f\"model_{prefix}\")\n",
    "        target[\"scores\"] = [None]\n",
    "        frame = plot_boxes(denormalized_road_roi_polygon, [target], torch.clone(original_image).numpy())\n",
    "        save_test_img(frame, output, f\"actual_{prefix}\")\n",
    "        \n",
    "        \n",
    "        print(\"Histograms\")\n",
    "        print(hist_cars)\n",
    "        print(hist_pedestrians)\n",
    "        save_hist(hist_cars, title=f\"Car prediction by Faster Rcnn {model_name}\", prefix=f\"car_{prefix}\")\n",
    "        save_hist(hist_pedestrians, title=f\"Pedestrian prediction by Faster Rcnn {model_name}\", prefix=f\"pedestrians_{prefix}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
