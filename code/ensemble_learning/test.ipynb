{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from torchvision.ops.boxes import box_iou\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2 \n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn \n",
    "from torchvision.models.detection import ssd300_vgg16, SSD300_VGG16_Weights, ssd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import datetime\n",
    "torch.manual_seed = 0\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from conf import *\n",
    "from inference.inference_helper import normalize_image, preprocess_image, inference_filter_prediction,denormalize_polygon\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from itertools import combinations, product\n",
    "\n",
    "model_path1 = \"../models/Good_FasterRcnn_V1_model.pth\"\n",
    "model_path2 = \"../models/Good_FasterRcnn_V2_model.pth\"\n",
    "model_path3 = \"../models/Good_SSD_model.pth\"\n",
    "yolo_path4 = \"../models/yolov8.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model1(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path1)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path1} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "def load_model2(num_classes=NUMBER_OF_CLASSES):\n",
    "    model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    state_dict= torch.load(model_path2)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path2} is loaded successfuly\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ssd_detection_model(num_classes=NUMBER_OF_CLASSES):\n",
    "    ssd_model = ssd300_vgg16(weights=False)\n",
    "    num_anchors = ssd_model.anchor_generator.num_anchors_per_location()\n",
    "    out_channels = [512,1024,512,256,256,256]\n",
    "    # ssd_model.head = ssd.SSDHead(out_channels, num_anchors, num_classes+1)\n",
    "    state_dict= torch.load(model_path3)\n",
    "    updated_state = {k.replace(\"module.\", \"\"): v for k,v in state_dict.items()}\n",
    "    ssd_model.load_state_dict(updated_state)\n",
    "    print(f\"MODEL from volume: {model_path3} is loaded successfuly\")\n",
    "\n",
    "    return ssd_model\n",
    "\n",
    "def load_yolo():\n",
    "    model = YOLO(yolo_path4)\n",
    "    return model\n",
    "\n",
    "def plot_boxes(normalized_road_roi_polygon, results, frame):\n",
    "    \"\"\"\n",
    "    Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "    :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "    :param frame: Frame which has been scored.\n",
    "    :return: Frame with bounding boxes and labels ploted on it.\n",
    "    \"\"\"\n",
    "    label_bg_white = (255, 255, 255)\n",
    "    if len(results) != 0:\n",
    "        for result in results:\n",
    "            for box, label,score in itertools.zip_longest(result['boxes'], result['labels'], result[\"scores\"]):\n",
    "                label = label.item()\n",
    "                if label <= len(BOX_COLOR):\n",
    "                    box_color = BOX_COLOR[label]\n",
    "                    x1, x2, x3, x4 = int(box[0].item()), int(box[1].item()), int(box[2].item()), int(box[3].item())\n",
    "                    cv2.rectangle(frame, (x1,x2),(x3,x4), box_color, 2)\n",
    "                    if score is not None:\n",
    "                        cv2.rectangle(frame, (x1, x2-25), (x1+150, x2), label_bg_white, -1)\n",
    "                        label_text = f'{class_to_label(label)}: {score:.2f}'\n",
    "                        cv2.putText(frame, label_text, (x1, x2 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.9, box_color, 2)\n",
    "    cv2.polylines(frame, [np.array(normalized_road_roi_polygon)], isClosed=True, color=(32, 32, 128), thickness=2)\n",
    "    return frame\n",
    "\n",
    "def class_to_label(label):\n",
    "    return IDX_TO_CLASSES[label]\n",
    "\n",
    "def save_test_img(img, target, prefix):\n",
    "    # img = img.permute(2,0,1).cpu().numpy()  # Convert to (height, width, channels)\n",
    "\n",
    "    # img = img.astype('uint8')\n",
    "    # img = img\n",
    "    # Draw bounding boxes on the image\n",
    "    print(target)\n",
    "    for box, label in zip(target['boxes'], target['labels']):\n",
    "        x, y, w, h = box.tolist()\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        # box_color = BOX_COLOR[label.item()]\n",
    "        print(label)\n",
    "        box_color = (255,255,255)\n",
    "        cv2.rectangle(img, (x, y), (w, h), box_color, 2)\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    if not os.path.exists(os.path.join(os.getcwd(), 'test_output')):\n",
    "        os.makedirs(os.path.join(os.getcwd(), 'test_output'))\n",
    "    # cv2.imshow(img)\n",
    "    img_path = f\"./test_output/output_image_{prefix}.png\"\n",
    "    cv2.imwrite(img_path, img)\n",
    "    return img_path\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader, 1):\n",
    "        data = list(image.to(device) for image in data)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data, targets)\n",
    "        print(f\"=====[ epoch {epoch} batch {batch_idx}  output of the model: {output}\")\n",
    "\n",
    "        loss = output[\"loss_classifier\"]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def run(model, train_loader):\n",
    "    epochs = 2\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, train_loader, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "def yolo_preprocess(img):\n",
    "    # grayscale = to_grayscale(img)\n",
    "    grayscale = img\n",
    "    grayscale = normalize_image(grayscale)\n",
    "    grayscale = torch.from_numpy(grayscale).float()\n",
    "    grayscale = grayscale.unsqueeze(0)\n",
    "    return grayscale\n",
    "\"\"\"\n",
    "To perform ensemble learning I have:\n",
    "1. IoU to create intersection mask -> we get boxes which are predicted by both models\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def perform_ensemble_inference(predictions): # ((a,a,a) (b,b,b))\n",
    "    final_prediction = []\n",
    "    zipped_predictions = list(zip(*predictions)) # (a,b), (a,b), (a,b)\n",
    "    print(len(predictions))\n",
    "    print(len(zipped_predictions))\n",
    "\n",
    "    for predictions_batch in zipped_predictions: # (a,b)\n",
    "        print(len(predictions_batch))\n",
    "        ensemble_voting(predictions_batch)\n",
    "        # filter_common_predictions(predictions_batch)\n",
    "    return final_prediction\n",
    "\n",
    "\n",
    "def ensemble_voting(predictions_batch, iou_threshold=0.6):\n",
    "    voting_result = {tuple(boxes): 1 for boxes in predictions_batch[0][\"boxes\"].tolist()}\n",
    "    comparison_tensor = predictions_batch[0][\"boxes\"]\n",
    "    print(\"voting_result: \", voting_result)\n",
    "    for prediction in predictions_batch[1:]:\n",
    "        boxes = prediction[\"boxes\"]\n",
    "        iou_mask = box_iou(comparison_tensor, boxes)\n",
    "        mask1 = iou_mask.sum(axis=1) > iou_threshold\n",
    "        mask2 = iou_mask.sum(axis=0) > iou_threshold\n",
    "\n",
    "        print(\"comparison_tensor: \", comparison_tensor)\n",
    "        print(\"boxes: \", boxes)\n",
    "\n",
    "        print(\"mask1: \", mask1)\n",
    "        print(\"mask2: \", mask2)\n",
    "\n",
    "        matching_boxes = comparison_tensor[mask1]\n",
    "        new_boxes = boxes[~mask2]\n",
    "        print(\"matching_boxes: \", matching_boxes)\n",
    "        print(\"new_boxes: \", new_boxes)\n",
    "        for box in matching_boxes:\n",
    "            box = tuple(box.tolist())\n",
    "            if box in voting_result:\n",
    "                voting_result[box] += 1\n",
    "            else:\n",
    "                voting_result[box] = 1\n",
    "        if len(new_boxes):\n",
    "            comparison_tensor = torch.cat((comparison_tensor, new_boxes))\n",
    "    print(\"voting_result: \",voting_result)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def filter_common_predictions(predictions_batch, iou_threshold=0.6): # (pred1, pred2)\n",
    "    num_of_predictions = len(predictions_batch)\n",
    "    predictions_batch = {(key,): prediction[\"boxes\"] for key, prediction in enumerate(predictions_batch)}\n",
    "    \n",
    "    print(\"predictions_batch: \", predictions_batch)\n",
    "    iou_mask = compute_iou_for_all_pairs(predictions_batch, iou_threshold) \n",
    "\n",
    "\n",
    "    partial_common_boxes = {(*i, j): predictions_batch[tuple(i)][mask] for (*i,j), mask in iou_mask.items()}\n",
    "    print(\"partial_common_boxes: \", partial_common_boxes)\n",
    "    iou_mask = compute_iou_for_all_pairs(partial_common_boxes, iou_threshold) \n",
    "    print(\"iou_mask 2: \", iou_mask)\n",
    "    partial_common_boxes = {(*i, j): partial_common_boxes[tuple(i)][mask] for (*i,j), mask in iou_mask.items()}\n",
    "    print(\"partial_common_boxes 2: \", partial_common_boxes)\n",
    "    iou_mask = compute_iou_for_all_pairs(partial_common_boxes, iou_threshold) \n",
    "    print(\"iou_mask 3: \", iou_mask)\n",
    "    partial_common_boxes = {(*i, j): partial_common_boxes[tuple(i)][mask] for (*i,j), mask in iou_mask.items()}\n",
    "    print(\"partial_common_boxes 3: \", partial_common_boxes)\n",
    "\n",
    "def compute_iou_for_all_pairs(predictions_batch, iou_threshold=0.6):\n",
    "    # Generate all pairs of indices for bounding_boxes_list\n",
    "    pairs = list(combinations(range(len(predictions_batch)), 2))\n",
    "\n",
    "    # Compute IoU for each pair of bounding box sets\n",
    "    iou_matrices = {}\n",
    "    for i, j in pairs:\n",
    "        predictions = list(predictions_batch.items())\n",
    "        key1, box1 = predictions[i]\n",
    "        key2, box2 = predictions[j]\n",
    "        intersecting_keys = len(set(key1).difference(key2))\n",
    "        print(\"INTERSECTION: \", intersecting_keys)\n",
    "        new_key = tuple(set(key1+key2))\n",
    "\n",
    "        print(f\"key1: {key1} box1 {box1}\")\n",
    "        print(f\"key2: {key2} box2 {box2}\")\n",
    "        if len(box1) > 0 and len(box2) > 0 and intersecting_keys == 1 and not new_key in iou_matrices:\n",
    "            iou_mask = box_iou(box1, box2).sum(axis=1)  > iou_threshold\n",
    "            print(f\"iou_mask: {iou_mask}\")\n",
    "            iou_matrices[new_key] = iou_mask\n",
    "    print(\"==========================\")\n",
    "    print(\"iou_matrices\", iou_matrices)\n",
    "    return iou_matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL from volume: ../models/Good_FasterRcnn_V1_model.pth is loaded successfuly\n",
      "MODEL from volume: ../models/Good_FasterRcnn_V2_model.pth is loaded successfuly\n",
      "MODEL from volume: ../models/Good_SSD_model.pth is loaded successfuly\n"
     ]
    }
   ],
   "source": [
    "model1 = load_model1()\n",
    "model2 = load_model2()\n",
    "model3 = get_ssd_detection_model()\n",
    "# model4 = load_yolo()\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "# model4.eval()\n",
    "\n",
    "original_image_sizes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 filtering: \n",
      "Filtered based on  polygon:  {'scores': tensor([0.9542, 0.9492, 0.9237, 0.9019]), 'labels': tensor([4, 4, 4, 4]), 'boxes': tensor([[305.3919, 513.8285, 384.6668, 600.6637],\n",
      "        [364.9731, 704.9017, 591.7959, 971.8295],\n",
      "        [316.7217, 457.6261, 384.8579, 490.2362],\n",
      "        [311.6656, 372.6617, 364.1157, 421.6015]])}\n",
      "AFTER CLEANING ON THE ROAD {'scores': tensor([0.9542, 0.9492, 0.9237, 0.9019]), 'labels': tensor([4, 4, 4, 4]), 'boxes': tensor([[305.3919, 513.8285, 384.6668, 600.6637],\n",
      "        [364.9731, 704.9017, 591.7959, 971.8295],\n",
      "        [316.7217, 457.6261, 384.8579, 490.2362],\n",
      "        [311.6656, 372.6617, 364.1157, 421.6015]])}\n",
      "Model2 filtering: \n",
      "Filtered based on  polygon:  {'scores': tensor([0.9391, 0.9262, 0.9215, 0.9159, 0.8990]), 'labels': tensor([4, 4, 4, 4, 4]), 'boxes': tensor([[ 301.0785,  517.4127,  391.3704,  599.2695],\n",
      "        [ 353.1155,  679.5331,  581.2241,  961.9435],\n",
      "        [ 316.4129,  446.1359,  388.3924,  495.4585],\n",
      "        [ 363.5381,  534.9156,  635.8593,  939.3203],\n",
      "        [ 275.2411,  744.0231,  562.9437, 1012.0065]])}\n",
      "AFTER CLEANING ON THE ROAD {'scores': tensor([0.9391, 0.9262, 0.9215, 0.9159, 0.8990]), 'labels': tensor([4, 4, 4, 4, 4]), 'boxes': tensor([[ 301.0785,  517.4127,  391.3704,  599.2695],\n",
      "        [ 353.1155,  679.5331,  581.2241,  961.9435],\n",
      "        [ 316.4129,  446.1359,  388.3924,  495.4585],\n",
      "        [ 363.5381,  534.9156,  635.8593,  939.3203],\n",
      "        [ 275.2411,  744.0231,  562.9437, 1012.0065]])}\n",
      "Model3 filtering: \n",
      "Filtered based on  polygon:  {'scores': tensor([0.8470, 0.5401]), 'labels': tensor([4, 4]), 'boxes': tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696]])}\n",
      "AFTER CLEANING ON THE ROAD {'scores': tensor([0.8470, 0.5401]), 'labels': tensor([4, 4]), 'boxes': tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696]])}\n",
      "3\n",
      "1\n",
      "3\n",
      "voting_result:  {(350.7064514160156, 652.2957153320312, 564.2510986328125, 978.9915771484375): 1, (311.2726745605469, 519.1985473632812, 388.5482482910156, 595.1695556640625): 1}\n",
      "comparison_tensor:  tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696]])\n",
      "boxes:  tensor([[301.0785, 517.4127, 391.3704, 599.2695],\n",
      "        [353.1155, 679.5331, 581.2241, 961.9435],\n",
      "        [316.4129, 446.1359, 388.3924, 495.4585]])\n",
      "mask1:  tensor([True, True])\n",
      "mask2:  tensor([ True,  True, False])\n",
      "matching_boxes:  tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696]])\n",
      "new_boxes:  tensor([[316.4129, 446.1359, 388.3924, 495.4585]])\n",
      "comparison_tensor:  tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696],\n",
      "        [316.4129, 446.1359, 388.3924, 495.4585]])\n",
      "boxes:  tensor([[305.3919, 513.8285, 384.6668, 600.6637],\n",
      "        [364.9731, 704.9017, 591.7959, 971.8295],\n",
      "        [316.7217, 457.6261, 384.8579, 490.2362],\n",
      "        [311.6656, 372.6617, 364.1157, 421.6015]])\n",
      "mask1:  tensor([True, True, True])\n",
      "mask2:  tensor([ True,  True,  True, False])\n",
      "matching_boxes:  tensor([[350.7065, 652.2957, 564.2511, 978.9916],\n",
      "        [311.2727, 519.1985, 388.5482, 595.1696],\n",
      "        [316.4129, 446.1359, 388.3924, 495.4585]])\n",
      "new_boxes:  tensor([[311.6656, 372.6617, 364.1157, 421.6015]])\n",
      "voting_result:  {(350.7064514160156, 652.2957153320312, 564.2510986328125, 978.9915771484375): 3, (311.2726745605469, 519.1985473632812, 388.5482482910156, 595.1695556640625): 3, (316.4129333496094, 446.13592529296875, 388.3923645019531, 495.4585266113281): 1}\n"
     ]
    }
   ],
   "source": [
    "image_dir = \"./real_images/simple.jpg\"\n",
    "image_dim = (960,1280)\n",
    "denormalized_road_roi_polygon = denormalize_polygon(image_dim, ROAD_ROI_POLYGON)\n",
    "\n",
    "image = cv2.imread(image_dir)\n",
    "grayscale = preprocess_image(image)\n",
    "grayscale = grayscale.unsqueeze(0)\n",
    "inputs = grayscale\n",
    "\n",
    "timer_model1 = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    outputs1 = model1(inputs)\n",
    "timer_model1 = datetime.datetime.now() - timer_model1 \n",
    "\n",
    "timer_model2 = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    outputs2 = model2(inputs)\n",
    "timer_model2 = datetime.datetime.now() - timer_model2\n",
    "\n",
    "timer_model3 = datetime.datetime.now()\n",
    "with torch.no_grad():\n",
    "    outputs3 = model3(inputs)\n",
    "timer_model3 = datetime.datetime.now() - timer_model3\n",
    "\n",
    "print(\"Model1 filtering: \")\n",
    "outputs1 = inference_filter_prediction(outputs1, denormalized_road_roi_polygon,iou_threshold=0.3)\n",
    "print(\"Model2 filtering: \")\n",
    "outputs2 = inference_filter_prediction(outputs2, denormalized_road_roi_polygon)\n",
    "print(\"Model3 filtering: \")\n",
    "outputs3 = inference_filter_prediction(outputs3, denormalized_road_roi_polygon, iou_threshold=0.3)\n",
    "\n",
    "final_prediction = perform_ensemble_inference([outputs3, outputs2, outputs1])\n",
    "\n",
    "# print(\"final_prediction: \", final_prediction)\n",
    "# print(\"outputs1: \", outputs1)\n",
    "# print(\"outputs3: \", outputs3)\n",
    "\n",
    "# \"\"\"\n",
    "# Common predictions are left without a change\n",
    "# Model1 * 0.7 + Model2*0.3\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# it = random.randint(0, 1000)\n",
    "# prefix=f\"detections-{it}\"\n",
    "# frame1 = plot_boxes(denormalized_road_roi_polygon, outputs1, np.copy(image))\n",
    "# frame3 = plot_boxes(denormalized_road_roi_polygon, outputs3, np.copy(image))\n",
    "# ensemble_frame = plot_boxes(denormalized_road_roi_polygon, final_prediction, np.copy(image))\n",
    "\n",
    "# for output1, output3, ensemble_pred in zip(outputs1,outputs3, final_prediction):\n",
    "    \n",
    "#     save_test_img(frame1, output1, f\"FasterRcnn_{prefix}\")\n",
    "#     save_test_img(frame3, output3, f\"SSD_{prefix}\")\n",
    "#     save_test_img(ensemble_frame, ensemble_pred, f\"Ensemble_{prefix}\")\n",
    "\n",
    "# print(f\"Model1: {timer_model1}\\nModel3: {timer_model3}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values: tensor([[3, 4, 5],\n",
      "        [3, 3, 3]]), \n",
      "ref_values: tensor([[1, 2, 3],\n",
      "        [3, 4, 5]])\n",
      "tensor([[False, False, False],\n",
      "        [ True, False, False]])\n",
      "values: tensor([[1, 2, 3],\n",
      "        [3, 4, 5]]), \n",
      "ref_values: tensor([[3, 4, 5],\n",
      "        [3, 3, 3]])\n",
      "tensor([[False, False, False],\n",
      "        [ True, False, False]])\n",
      "Output: {}\n"
     ]
    }
   ],
   "source": [
    "x = {(0,1): torch.tensor([[1,2,3],[3,4,5]]),\n",
    "     (0,2): torch.tensor([[3,4,5],[3,3,3]]),\n",
    "     (1,2): torch.tensor([[3,4,5],[4,4,4]])}\n",
    "\n",
    "\"output: (0,1,2,3): [3],(0,1):[1,2], (0,2):[4])\"\n",
    "merged_dict = {}\n",
    "\n",
    "for ref_key, ref_values in x.items():\n",
    "    merged_key = []\n",
    "    for key, values in x.items():\n",
    "        if ref_key[0] == key[0] and ref_key[1] != key[1]:\n",
    "            mask = torch.eq(values, ref_values)\n",
    "            print(f\"values: {values}, \\nref_values: {ref_values}\")\n",
    "            print(mask) \n",
    "            # mask = [True if item in ref_values else False for item in values]\n",
    "            # print(f\"ref_value: {ref_values}, values: {values}\")\n",
    "            # print(mask)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Output:\", merged_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
